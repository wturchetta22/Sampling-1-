{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate All Statistics\n",
    "Here's the idea\n",
    "- This notebook is made to be able to run all of our statistics very quickly (well not quickly but at least with one button push rather than hundreds) across all sample sizes, and runs within that\n",
    "- End goal of this notebook is to get a table where all 6 statistics are computed in one output per one sample size - for a more detailed look into each of the statistics and what goes into them you can look into the individual notebooks\n",
    "- This is going to be fairly nasty looking but we did this so we can press one button and get all the statistics all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx # documentation at https://networkx.org/documentation/\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/web-Stanford.txt\", sep=\"\\t\")\n",
    "in_degree_OG = data.groupby(\"ToNode\").count()[\"FromNode\"] #for in degree statistic\n",
    "out_degree_OG = data.groupby(\"FromNode\").count()[\"ToNode\"] #for out degree statistic\n",
    "G_Original = nx.DiGraph()\n",
    "G_Original = nx.from_pandas_edgelist(data, \"FromNode\", \"ToNode\", create_using=nx.DiGraph())\n",
    "wcc_OG = nx.weakly_connected_components(G_Original)\n",
    "wcc_sizes_OG = collections.Counter([len(wcc) for wcc in wcc_OG]).keys()\n",
    "scc_OG = nx.strongly_connected_components(G_Original)\n",
    "scc_sizes_OG = collections.Counter([len(wcc) for wcc in scc_OG]).keys()\n",
    "cc_OG = nx.average_clustering(G_Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_OG = nx.clustering(G_Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_nodes = np.unique(np.array(data[\"FromNode\"]))\n",
    "edge_holder = {}\n",
    "for nodes in list_of_nodes:\n",
    "    outlinks = list(data[data[\"FromNode\"] == nodes][\"ToNode\"])\n",
    "    edge_holder[nodes] = set(outlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_plot_3_OG = counting(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestcc = max(nx.weakly_connected_components(G_Original), key=len)\n",
    "edge_holder = {}\n",
    "for nodes in list_of_nodes:\n",
    "    if(nodes not in largestcc):\n",
    "        continue\n",
    "    outlinks = list(data[data[\"FromNode\"] == nodes][\"ToNode\"])\n",
    "    filtered = list(filter(lambda x: x in largestcc, outlinks))\n",
    "    if(len(filtered) > 0):\n",
    "        edge_holder[nodes] = set(filtered)\n",
    "\n",
    "hop_plot_3_wcc_OG = counting(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indegree():\n",
    "    in_degree_sample = input_data.groupby(\"ToNode\").count()[\"FromNode\"]\n",
    "    return stats.ks_2samp(in_degree_OG, in_degree_sample)[0] #returns the d-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdegree():\n",
    "    out_degree_sample = input_data.groupby(\"FromNode\").count()[\"ToNode\"]\n",
    "    return stats.ks_2samp(out_degree_OG, out_degree_sample)[0] #returns the d-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCC():\n",
    "    G_sample = nx.DiGraph()\n",
    "    G_sample = nx.from_pandas_edgelist(input_data, \"FromNode\", \"ToNode\", create_using=nx.DiGraph())\n",
    "    wcc_sample = nx.weakly_connected_components(G_sample)\n",
    "    wcc_sizes_sample = collections.Counter([len(wcc) for wcc in wcc_sample]).keys()\n",
    "    return stats.ks_2samp(list(wcc_sizes_OG), list(wcc_sizes_sample))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCC():\n",
    "    G_sample = nx.DiGraph()\n",
    "    G_sample = nx.from_pandas_edgelist(input_data, \"FromNode\", \"ToNode\", create_using=nx.DiGraph())\n",
    "    scc_sample = nx.strongly_connected_components(G_sample)\n",
    "    scc_sizes_sample = collections.Counter([len(wcc) for wcc in scc_sample]).keys()\n",
    "    return stats.ks_2samp(list(scc_sizes_OG), list(scc_sizes_sample))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringCoef():\n",
    "    G_sample = nx.DiGraph()\n",
    "    G_sample = nx.from_pandas_edgelist(input_data, \"FromNode\", \"ToNode\", create_using=nx.DiGraph())\n",
    "    cc_sample = nx.clustering(G_sample)\n",
    "    return stats.ks_2samp(list(cc_OG), list(cc_sample))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hopping(h, edge_holder): #now this returns all edges that can be reached in some amount of hops\n",
    "    #this works for two steps now need to make it work for 3,4, etc...\n",
    "    #first step is for each h create a new \"edge_holder\" that holds the elements it's connected ot in h steps\n",
    "    edge_holder2 = edge_holder.copy()\n",
    "    for nodes in edge_holder:\n",
    "        last_nodes = edge_holder[nodes]\n",
    "        hops = h\n",
    "        while(hops > 1):\n",
    "            temp = set()\n",
    "            for outlinks in last_nodes:\n",
    "                if(outlinks in edge_holder):\n",
    "                    temp = set.union(temp, edge_holder[outlinks])            \n",
    "            edge_holder2[nodes] = set.union(temp, edge_holder2[nodes])\n",
    "            hops = hops - 1\n",
    "            last_nodes = temp\n",
    "    \n",
    "    \n",
    "            \n",
    "    return edge_holder2\n",
    "\n",
    "def counting(num_steps, edge_holder): #what actually needs to be run for hop plot to run\n",
    "    e = hopping(num_steps, edge_holder);\n",
    "    pairs = 0;\n",
    "    for nodes in e:\n",
    "        for outlinks in e[nodes]:\n",
    "            if(outlinks in e and nodes in e[outlinks]):\n",
    "                pairs += 1;\n",
    "    \n",
    "    return int(pairs/2); #since we end up double counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_holder_normal():\n",
    "    list_of_nodes = np.unique(np.array(input_data[\"FromNode\"]))\n",
    "    edge_holder = {}\n",
    "    for nodes in list_of_nodes:\n",
    "        outlinks = list(data[data[\"FromNode\"] == nodes][\"ToNode\"])\n",
    "        edge_holder[nodes] = set(outlinks)\n",
    "    return edge_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_holder_wcc():\n",
    "    G_smp = nx.DiGraph()\n",
    "    G_smp = nx.from_pandas_edgelist(input_data, \"FromNode\", \"ToNode\", create_using=nx.DiGraph())\n",
    "    largestcc = max(nx.weakly_connected_components(G_smp), key=len)\n",
    "    edge_holder = {}\n",
    "    for nodes in list_of_nodes:\n",
    "        if(nodes not in largestcc):\n",
    "            continue\n",
    "        outlinks = list(input_data[input_data[\"FromNode\"] == nodes][\"ToNode\"])\n",
    "        filtered = list(filter(lambda x: x in largestcc, outlinks))\n",
    "        if(len(filtered) > 0):\n",
    "            edge_holder[nodes] = set(filtered)\n",
    "    return edge_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssizes = [\"5%\", \"10%\", \"15%\", \"20%\"]\n",
    "runnumbers = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "typeofsamples = [\"FF\", \"RNE\", \"RW\", \"RN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"RW5%\" : [], \"RNE5%\": [], \"FF5%\": [], \"RN5%\": [],\n",
    "       \"RW10%\" : [], \"RNE10%\": [], \"FF10%\": [], \"RN10%\": [], \n",
    "      \"RW15%\" : [], \"RNE15%\": [], \"FF15%\": [], \"RN15%\": [], \n",
    "       \"RW20%\" : [], \"RNE20%\": [], \"FF20%\": [], \"RN20%\": [], \n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {\"RW5%\" : [], \"RNE5%\": [], \"FF5%\": [], \"RN5%\": [],\n",
    "       \"RW10%\" : [], \"RNE10%\": [], \"FF10%\": [], \"RN10%\": [], \n",
    "      \"RW15%\" : [], \"RNE15%\": [], \"FF15%\": [], \"RN15%\": [], \n",
    "       \"RW20%\" : [], \"RNE20%\": [], \"FF20%\": [], \"RN20%\": [], \n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Samples/5%/FF/OutputFF5%1.csv\n",
      "./Samples/5%/FF/OutputFF5%2.csv\n",
      "./Samples/5%/FF/OutputFF5%3.csv\n",
      "./Samples/5%/FF/OutputFF5%4.csv\n",
      "./Samples/5%/FF/OutputFF5%5.csv\n",
      "./Samples/5%/RNE/OutputRNE5%1.csv\n",
      "./Samples/5%/RNE/OutputRNE5%2.csv\n",
      "./Samples/5%/RNE/OutputRNE5%3.csv\n",
      "./Samples/5%/RNE/OutputRNE5%4.csv\n",
      "./Samples/5%/RNE/OutputRNE5%5.csv\n",
      "./Samples/5%/RW/OutputRW5%1.csv\n",
      "./Samples/5%/RW/OutputRW5%2.csv\n",
      "./Samples/5%/RW/OutputRW5%3.csv\n",
      "./Samples/5%/RW/OutputRW5%4.csv\n",
      "./Samples/5%/RW/OutputRW5%5.csv\n",
      "./Samples/5%/RN/OutputRN5%1.csv\n",
      "./Samples/5%/RN/OutputRN5%2.csv\n",
      "./Samples/5%/RN/OutputRN5%3.csv\n",
      "./Samples/5%/RN/OutputRN5%4.csv\n",
      "./Samples/5%/RN/OutputRN5%5.csv\n",
      "./Samples/10%/FF/OutputFF10%1.csv\n",
      "./Samples/10%/FF/OutputFF10%2.csv\n",
      "./Samples/10%/FF/OutputFF10%3.csv\n",
      "./Samples/10%/FF/OutputFF10%4.csv\n",
      "./Samples/10%/FF/OutputFF10%5.csv\n",
      "./Samples/10%/RNE/OutputRNE10%1.csv\n",
      "./Samples/10%/RNE/OutputRNE10%2.csv\n",
      "./Samples/10%/RNE/OutputRNE10%3.csv\n",
      "./Samples/10%/RNE/OutputRNE10%4.csv\n",
      "./Samples/10%/RNE/OutputRNE10%5.csv\n",
      "./Samples/10%/RW/OutputRW10%1.csv\n",
      "./Samples/10%/RW/OutputRW10%2.csv\n",
      "./Samples/10%/RW/OutputRW10%3.csv\n",
      "./Samples/10%/RW/OutputRW10%4.csv\n",
      "./Samples/10%/RW/OutputRW10%5.csv\n",
      "./Samples/10%/RN/OutputRN10%1.csv\n",
      "./Samples/10%/RN/OutputRN10%2.csv\n",
      "./Samples/10%/RN/OutputRN10%3.csv\n",
      "./Samples/10%/RN/OutputRN10%4.csv\n",
      "./Samples/10%/RN/OutputRN10%5.csv\n",
      "./Samples/15%/FF/OutputFF15%1.csv\n",
      "./Samples/15%/FF/OutputFF15%2.csv\n",
      "./Samples/15%/FF/OutputFF15%3.csv\n",
      "./Samples/15%/FF/OutputFF15%4.csv\n",
      "./Samples/15%/FF/OutputFF15%5.csv\n",
      "./Samples/15%/RNE/OutputRNE15%1.csv\n",
      "./Samples/15%/RNE/OutputRNE15%2.csv\n",
      "./Samples/15%/RNE/OutputRNE15%3.csv\n",
      "./Samples/15%/RNE/OutputRNE15%4.csv\n",
      "./Samples/15%/RNE/OutputRNE15%5.csv\n",
      "./Samples/15%/RW/OutputRW15%1.csv\n",
      "./Samples/15%/RW/OutputRW15%2.csv\n",
      "./Samples/15%/RW/OutputRW15%3.csv\n",
      "./Samples/15%/RW/OutputRW15%4.csv\n",
      "./Samples/15%/RW/OutputRW15%5.csv\n",
      "./Samples/15%/RN/OutputRN15%1.csv\n",
      "./Samples/15%/RN/OutputRN15%2.csv\n",
      "./Samples/15%/RN/OutputRN15%3.csv\n",
      "./Samples/15%/RN/OutputRN15%4.csv\n",
      "./Samples/15%/RN/OutputRN15%5.csv\n",
      "./Samples/20%/FF/OutputFF20%1.csv\n",
      "./Samples/20%/FF/OutputFF20%2.csv\n",
      "./Samples/20%/FF/OutputFF20%3.csv\n",
      "./Samples/20%/FF/OutputFF20%4.csv\n",
      "./Samples/20%/FF/OutputFF20%5.csv\n",
      "./Samples/20%/RNE/OutputRNE20%1.csv\n",
      "./Samples/20%/RNE/OutputRNE20%2.csv\n",
      "./Samples/20%/RNE/OutputRNE20%3.csv\n",
      "./Samples/20%/RNE/OutputRNE20%4.csv\n",
      "./Samples/20%/RNE/OutputRNE20%5.csv\n",
      "./Samples/20%/RW/OutputRW20%1.csv\n",
      "./Samples/20%/RW/OutputRW20%2.csv\n",
      "./Samples/20%/RW/OutputRW20%3.csv\n",
      "./Samples/20%/RW/OutputRW20%4.csv\n",
      "./Samples/20%/RW/OutputRW20%5.csv\n",
      "./Samples/20%/RN/OutputRN20%1.csv\n",
      "./Samples/20%/RN/OutputRN20%2.csv\n",
      "./Samples/20%/RN/OutputRN20%3.csv\n",
      "./Samples/20%/RN/OutputRN20%4.csv\n",
      "./Samples/20%/RN/OutputRN20%5.csv\n"
     ]
    }
   ],
   "source": [
    "for ssize in ssizes:\n",
    "    for typeofsample in typeofsamples:\n",
    "        keyname = typeofsample + ssize #keeping track of where to store things\n",
    "        ind = []\n",
    "        outd = []\n",
    "        wcc = []\n",
    "        scc = []\n",
    "        hopnormal = []\n",
    "        hopwcc = []\n",
    "        cc = []\n",
    "        for runnumber in runnumbers:\n",
    "            \n",
    "            name = \"./Samples/\" + ssize + \"/\" + typeofsample + \"/\" + \"Output\" + typeofsample + ssize + runnumber + \".csv\"\n",
    "            input_data = pd.read_csv(name);\n",
    "#             ind.append(indegree())\n",
    "#             outd.append(outdegree())\n",
    "#             wcc.append(WCC())\n",
    "#             scc.append(SCC())\n",
    "#             eh = edge_holder_normal()\n",
    "#             hopnormal.append(counting(3, eh))\n",
    "#             eh2 = edge_holder_wcc()\n",
    "#             hopwcc.append(counting(3, eh))\n",
    "#             cc.append(clusteringCoef())\n",
    "    \n",
    "    \n",
    "#         dic[keyname].append(ind)\n",
    "#         dic[keyname].append(outd)\n",
    "#         dic[keyname].append(wcc)\n",
    "#         dic[keyname].append(scc)\n",
    "#         dic[keyname].append(hopnormal)\n",
    "#         dic[keyname].append(hopwcc)\n",
    "#         dic[keyname].append(cc)\n",
    "            \n",
    "            \n",
    "#         print(dic)\n",
    "# op = pd.DataFrame.from_dict(dic)\n",
    "# op.to_csv(\"Finally?.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
